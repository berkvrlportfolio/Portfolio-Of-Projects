{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e1134b7",
   "metadata": {},
   "source": [
    "Graph Theory: A basestation map of any given are\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba971a3",
   "metadata": {},
   "source": [
    "I created this code in my previous work as a telecommunications engineer. This code utilizes Graph Theory and takes a dataset of latitude & langitude datas of a base station and creates a graph of connections between the stations.\n",
    "The Dataset i had was a list of base stations in Istanbul and their location data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d151da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Created on Mon Jan  9 09:15:43 2023\n",
    "@author: berk.varol\n",
    "\"\"\"\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from pandas import read_excel as rc\n",
    "import math\n",
    "from haversine import haversine\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "\n",
    "#HARVESINE TAKES DISTANCE DATA IN ACCORDANCE TO EARTHS SHAPE!\n",
    "\n",
    "#reading the excel sheet\n",
    "df = pd.read_excel(\"Dataset.xlsx\", header=0)\n",
    "print (df)\n",
    "\n",
    "\n",
    "#taking nodes\n",
    "nodes1=df.loc[:,['Site_A','Latitude_A','Longitude_A']] #.loc to export spesific rows of data\n",
    "nodes2=df.loc[:,['Site_B','Latitude_B','Longitude_B']]\n",
    "\n",
    "# changing the column headers to merge them together\n",
    "nodes1.columns = ['SiteName', 'Latitude', 'Longitude']\n",
    "nodes2.columns = ['SiteName', 'Latitude', 'Longitude']\n",
    "\n",
    "#merge nodes data\n",
    "nodes=pd.concat([nodes1,nodes2],axis=0)\n",
    "nodes = nodes.reset_index(drop=True) # index resetliyo\n",
    "\n",
    "#if in future we will have duplicates (one node connecting to several) this \n",
    "#will help us drop the duplicates.\n",
    "nodes=nodes.drop_duplicates()\n",
    "print(nodes)\n",
    "\n",
    "\n",
    "# Define the graph -nodes info part\n",
    "G = nx.Graph()\n",
    "\n",
    "node_names =np.array(nodes.loc[:,'SiteName'])\n",
    "lats = np.array(nodes.loc[:,'Latitude'].tolist())\n",
    "lons = np.array(nodes.loc[:,'Longitude'].tolist())\n",
    "\n",
    "\n",
    "\n",
    "#add node\n",
    "for i in range(0, len(nodes)):\n",
    "    node_name=node_names[i]\n",
    "    lat=lats[i]\n",
    "    lon=lons[i]\n",
    "    G.add_node(node_name, pos=(lat,lon))\n",
    "\n",
    "    \n",
    "    \n",
    "#edges info part\n",
    "weights=[]\n",
    "\n",
    "node_name_as=np.array(df.loc[:,'Site_A'])\n",
    "node_name_bs =np.array(df.loc[:,'Site_B'])    \n",
    "\n",
    "for i in range (0, len(df)):\n",
    "    lat1=df.loc[i,'Latitude_A']\n",
    "    lat2=df.loc[i,'Latitude_B']\n",
    "    lon1=df.loc[i,'Longitude_A']\n",
    "    lon2=df.loc[i,'Longitude_B']\n",
    "    \n",
    "    dist=haversine((lat1, lon1), (lat2, lon2))\n",
    "    weights=np.append(weights, dist)    \n",
    "    \n",
    "    node_name_a=node_name_as[i]\n",
    "    node_name_b=node_name_bs[i]\n",
    "    weight=weights[i]\n",
    "    G.add_edge(node_name_a,node_name_b,weight=weight)\n",
    "\n",
    "print(G)\n",
    "# Extract the node positions\n",
    "pos = nx.get_node_attributes(G, 'pos')\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(3,figsize=(24,24)) \n",
    "nx.draw(G,pos, with_labels=True,node_size=60,font_size=2)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
